# 阶段五：测试、部署与总结

本文档指导你完成 Deep-Research-AI-Agent 项目复现的最后阶段，包括测试策略、部署建议以及对整个复现过程的总结。

## 任务 5.1：制定测试策略

**目标**：为项目定义一个全面的测试策略，确保代码质量和功能的稳定性。虽然之前的步骤已经提到了单元测试的准备，这里我们将更系统地考虑。

**LLM 提示词**：
```
请为我概述一个针对 Next.js 全栈应用的测试策略。这个策略应该包含以下几个层面，并请针对 Deep-Research-AI-Agent 项目的特点给出具体建议：

1.  **单元测试 (Unit Tests)**：
    *   应该测试哪些类型的单元？(例如：React 组件、工具函数 `lib/utils.ts`、Zustand store 的 actions 和 selectors、API 路由中的辅助函数)。
    *   建议使用什么测试库？(例如 Jest, React Testing Library)。
    *   如何为 `components/ui/` 中的 Shadcn UI 组件（如果进行了自定义修改）和自定义的业务组件 (如 `SearchResultsDisplay`, `ReportDisplay`) 准备单元测试？(提示：关注 props 的传递、条件渲染逻辑、用户交互的模拟)。
    *   如何为 API 路由 (`app/api/**/*.ts`) 中的核心逻辑（例如数据转换、外部 API 调用前的参数构造、错误处理逻辑等，不包括实际的外部 API 调用本身，那些应被 mock）准备单元测试？

2.  **集成测试 (Integration Tests)**：
    *   应该测试哪些模块之间的集成？(例如：前端页面与 Zustand store 的集成、前端页面通过 `useChat` 与后端 API `/api/chat` 的交互、后端 `/api/chat` 与 `/api/search` 或直接与 Exa/OpenRouter SDK 的集成)。
    *   如何测试前端组件（如 `app/page.tsx`）与 `useChat` hook 和后端 API `/api/chat` 的完整交互流程（mock 掉实际的 LLM 和 Search API 调用，只测试数据流和组件状态更新）？
    *   如何测试后端 API 路由之间的调用或者 API 路由与外部服务 SDK（如 Exa, OpenRouter）的集成点（同样，mock 掉真正的外部网络请求，专注于数据格式和错误传递）？

3.  **端到端测试 (End-to-End Tests)**：
    *   覆盖哪些关键用户流程？(例如：用户输入研究主题 -> 查看 LLM 初步响应 -> （如果触发搜索）查看搜索结果 -> 查看最终研究报告 -> 主题切换)。
    *   建议使用什么 E2E 测试框架？(例如 Playwright, Cypress)。
    *   如何准备一个简单的 E2E 测试脚本来验证核心的研究流程？

请提醒我，对于 LLM 交互和外部 API 调用，测试的重点是我们的代码如何正确地准备数据给它们、如何处理它们的响应（包括成功和错误情况），以及如何在它们不可用或返回预期外结果时优雅降级。我们不测试 LLM 本身的智能或外部 API 的可靠性。
```

**实践与测试**：
1.  **创建测试文件结构**：
    *   根据 LLM 的建议，开始在项目中创建相应的测试文件。例如：
        *   `components/my-component.test.tsx`
        *   `lib/utils.test.ts`
        *   `store/research-store.test.ts`
        *   `app/api/chat/route.test.ts`
    *   可以先创建空的测试文件，或者包含一个非常简单的占位测试用例。
2.  **配置测试环境**：
    *   如果选择了 Jest，需要安装并配置 Jest (`jest.config.js` 或在 `package.json` 中配置)。确保 Next.js 的特定配置（如 SWC）得到支持。
    *   安装 React Testing Library。
    *   如果选择 Playwright/Cypress，按照其官方文档进行安装和初始化配置。
3.  **编写并运行一个简单的单元测试**：
    *   例如，为 `lib/utils.ts` 中的一个简单函数编写一个单元测试，并尝试运行它，确保测试环境配置正确。
    *   **提示**：LLM 可以帮助你为一个具体的、简单的函数生成一个示例性的单元测试的描述，然后你（或另一个LLM）根据这个描述来实际编写（但此文档不包含实际代码）。

## 任务 5.2：准备项目构建与部署

**目标**：了解如何构建生产版本的 Next.js 应用，并考虑部署到常见的托管平台。

**LLM 提示词**：
```
请提供关于构建和部署 Next.js 应用 (特别是像 Deep-Research-AI-Agent 这样包含 API 路由和需要环境变量的应用) 的通用指南。

1.  **构建生产版本**：
    *   执行什么命令来构建 Next.js 应用的生产版本？(`npm run build`)
    *   构建过程会生成什么？(通常是 `.next` 文件夹下的优化过的静态资源、serverless functions 等)。

2.  **环境变量配置**：
    *   在部署时，如何在生产环境中安全地设置 `OPENROUTER_API_KEY` 和 `EXA_API_KEY`？不同平台（如 Vercel, Netlify, AWS Amplify, Docker 容器）通常有哪些设置环境变量的方式？

3.  **选择部署平台**：
    *   对于 Next.js 应用，有哪些推荐的部署平台？(Vercel 是首选，因为它与 Next.js 的集成最好)。
    *   简要说明在 Vercel 上部署 Next.js 项目的基本步骤 (例如：连接 Git 仓库、配置构建命令和环境变量)。

4.  **启动生产服务器**：
    *   如果不是部署到像 Vercel 这样的 PaaS 平台，而是自己管理服务器 (例如使用 Docker 或 Node.js 服务器)，如何启动 Next.js 的生产服务器？(`npm run start`)

5.  **部署前检查清单**：
    *   部署前应该检查哪些事项？(例如：所有 API 密钥都已在生产环境中正确配置、依赖项已更新、Linting 和类型检查通过、关键 E2E 测试通过等)。
```

**实践与测试**：
1.  **本地生产构建测试**：
    *   在本地运行 `npm run build` 命令，确保项目能够成功构建，没有错误。
    *   构建成功后，运行 `npm run start` 来在本地启动生产模式的服务器。
    *   在浏览器中打开 `http://localhost:3000` (或其他指定端口)，测试应用的核心功能是否在生产模式下依然正常工作。此时 API 调用会真实发生（如果配置了有效的密钥）。
2.  **(可选) Vercel 部署尝试**：
    *   如果你的项目代码已经推送到 GitHub/GitLab/Bitbucket 仓库，可以尝试将其连接到 Vercel 账户并进行部署。
    *   在 Vercel 的项目设置中配置好必要的环境变量。
    *   观察 Vercel 的构建和部署日志，确保过程顺利完成。
    *   访问 Vercel 提供的域名，测试线上版本的功能。

## 任务 5.3：项目复现总结与展望

**目标**：回顾整个项目复现过程，总结学到的知识点，并思考未来可能的改进方向。

**LLM 提示词**：
```
请帮我为 Deep-Research-AI-Agent 项目的复现过程写一个总结。
总结应包含：
1.  **项目核心能力回顾**：简要重申项目的主要功能 (AI驱动的研究、搜索集成、报告生成)。
2.  **关键技术栈回顾**：列出在复现过程中使用的主要技术 (Next.js App Router, TypeScript, Tailwind CSS, Shadcn UI, Vercel AI SDK, Zustand, OpenRouter, Exa API)。
3.  **主要实现模块**：回顾项目的主要组成部分 (项目设置、API 路由、前端UI、状态管理、高级研究流程)。
4.  **学到的关键概念**：在复现过程中可能学到的重要概念 (例如：全栈 Next.js 开发、流式响应处理、LLM 提示工程、Function Calling/Tool Use、客户端状态管理、API 集成、响应式设计)。

同时，请基于当前的项目成果，提出一些未来可以探索或改进的方向：
1.  **更精细的 LLM 提示工程**：如何进一步优化与 LLM 的交互，以获得更准确、更深入的研究结果？
2.  **用户认证与个性化**：如何加入用户登录，保存用户的研究历史和偏好设置？
3.  **数据持久化**：如何将生成的研究报告、用户反馈等信息保存到数据库中？
4.  **更丰富的 UI/UX**：例如，研究过程的可视化、更复杂的报告编辑和导出功能。
5.  **错误处理与容错**：如何使系统在外部 API 故障或 LLM 返回意外内容时更加健壮？
6.  **成本控制与监控**：对于调用付费 LLM 和搜索 API，如何监控使用量和成本，并设置预算提醒？
7.  **支持更多 LLM 和搜索提供商**：如何使系统更容易扩展以支持新的 AI 服务？
```

**实践**：
1.  **回顾文档**：通读之前创建的 `01`到 `04` 的 Markdown 文档，回顾每个阶段的任务和学习点。
2.  **整理笔记**：根据 LLM 生成的总结框架，结合自己的理解和实践经验，整理一份个性化的项目总结和学习心得。
3.  **思考未来**：针对 LLM 提出的未来改进方向，思考哪些是你最感兴趣或认为最有价值的，并可以作为后续学习和实践的目标。

---

恭喜你！完成这个阶段后，你不仅拥有了一个功能相对完整的 Deep-Research-AI-Agent 项目的复现版本，还对整个开发流程、测试和部署有了更全面的理解。希望这个复现指南对你有所帮助！ 